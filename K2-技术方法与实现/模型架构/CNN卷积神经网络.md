# CNN å·ç§¯ç¥ç»ç½‘ç»œ

> **ä½œç”¨**ï¼šä¸“é—¨å¤„ç†ç½‘æ ¼æ•°æ®ï¼ˆå¦‚å›¾åƒï¼‰çš„æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œæ˜¯è®¡ç®—æœºè§†è§‰çš„åŸºç¡€
> **å±‚çº§**ï¼šK2-æŠ€æœ¯æ–¹æ³•ä¸å®ç° â†’ æ¨¡å‹æ¶æ„  
> **å…³è”**ï¼š[[PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶]]ã€[[TensorFlowæ·±åº¦å­¦ä¹ æ¡†æ¶]]ã€[[Transformeræ¶æ„åŸç†]]ã€[[å¤§è¯­è¨€æ¨¡å‹åŸºç¡€]]ã€[[K1-åŸºç¡€ç†è®ºä¸æ¦‚å¿µ/æ ¸å¿ƒæ¦‚å¿µ/æŸå¤±å‡½æ•°ä¸è®­ç»ƒè°ƒä¼˜æœ¯è¯­åè¯åº“|æœ¯è¯­åè¯åº“ï¼ˆå¤§ç™½è¯å¯¹ç…§ï¼‰]]

---

## ğŸ“Œ æ¦‚å¿µå®šä¹‰

**å·ç§¯ç¥ç»ç½‘ç»œï¼ˆConvolutional Neural Networkï¼ŒCNNï¼‰**æ˜¯ä¸€ç§ä¸“é—¨ç”¨äºå¤„ç†å…·æœ‰ç½‘æ ¼ç»“æ„æ•°æ®çš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œç‰¹åˆ«é€‚ç”¨äºå›¾åƒè¯†åˆ«ã€è®¡ç®—æœºè§†è§‰ä»»åŠ¡ã€‚CNNé€šè¿‡å·ç§¯å±‚ã€æ± åŒ–å±‚ç­‰ç‰¹æ®Šç»“æ„ï¼Œèƒ½å¤Ÿè‡ªåŠ¨å­¦ä¹ å’Œæå–æ•°æ®çš„ç©ºé—´ç‰¹å¾ã€‚

### ğŸ¯ æ ¸å¿ƒä¼˜åŠ¿
- **ç©ºé—´ä¸å˜æ€§**ï¼šå¯¹å›¾åƒçš„å¹³ç§»ã€æ—‹è½¬å…·æœ‰ä¸€å®šçš„é²æ£’æ€§
- **å‚æ•°å…±äº«**ï¼šåŒä¸€å·ç§¯æ ¸åœ¨æ•´ä¸ªç‰¹å¾å›¾ä¸Šå…±äº«ï¼Œå¤§å¹…å‡å°‘å‚æ•°é‡
- **å±€éƒ¨è¿æ¥**ï¼šæ¯ä¸ªç¥ç»å…ƒåªè¿æ¥è¾“å…¥çš„å±€éƒ¨åŒºåŸŸï¼Œé™ä½è®¡ç®—å¤æ‚åº¦
- **å±‚æ¬¡ç‰¹å¾å­¦ä¹ **ï¼šä»ä½çº§è¾¹ç¼˜ç‰¹å¾åˆ°é«˜çº§è¯­ä¹‰ç‰¹å¾çš„é€å±‚æŠ½è±¡

---

## ğŸ—ï¸ æ¶æ„ç»„ä»¶

### ğŸ”§ æ ¸å¿ƒå±‚ç»“æ„

```mermaid
graph TD
    A[è¾“å…¥å›¾åƒ] --> B[å·ç§¯å±‚ Conv]
    B --> C[æ¿€æ´»å‡½æ•° ReLU]
    C --> D[æ± åŒ–å±‚ Pooling]
    D --> E[å·ç§¯å±‚ Conv]
    E --> F[æ¿€æ´»å‡½æ•° ReLU]
    F --> G[æ± åŒ–å±‚ Pooling]
    G --> H[å…¨è¿æ¥å±‚ FC]
    H --> I[è¾“å‡ºå±‚]
    
    J[ç‰¹å¾å›¾] -.-> B
    K[å·ç§¯æ ¸/æ»¤æ³¢å™¨] -.-> B
    L[ç‰¹å¾é™ç»´] -.-> D
    M[åˆ†ç±»/é¢„æµ‹] -.-> H
```

### ğŸ’¡ è¯¦ç»†ç»„ä»¶è¯´æ˜

#### 1ï¸âƒ£ å·ç§¯å±‚ï¼ˆConvolutional Layerï¼‰
```python
import torch
import torch.nn as nn

# PyTorchä¸­çš„2Då·ç§¯å±‚
conv_layer = nn.Conv2d(
    in_channels=3,     # è¾“å…¥é€šé“æ•°ï¼ˆRGBå›¾åƒä¸º3ï¼‰
    out_channels=64,   # è¾“å‡ºé€šé“æ•°ï¼ˆå·ç§¯æ ¸æ•°é‡ï¼‰
    kernel_size=3,     # å·ç§¯æ ¸å¤§å° 3x3
    stride=1,          # æ­¥å¹…
    padding=1          # å¡«å……
)

# å·ç§¯æ“ä½œçš„æ•°å­¦åŸç†
# è¾“å‡ºç‰¹å¾å›¾å¤§å°è®¡ç®—å…¬å¼ï¼š
# Output = (Input + 2*Padding - Kernel_size) / Stride + 1
```

#### 2ï¸âƒ£ æ± åŒ–å±‚ï¼ˆPooling Layerï¼‰
```python
# æœ€å¤§æ± åŒ–
max_pool = nn.MaxPool2d(kernel_size=2, stride=2)

# å¹³å‡æ± åŒ–
avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)

# è‡ªé€‚åº”æ± åŒ–ï¼ˆè¾“å‡ºå›ºå®šå°ºå¯¸ï¼‰
adaptive_pool = nn.AdaptiveAvgPool2d(output_size=(7, 7))
```

#### 3ï¸âƒ£ æ¿€æ´»å‡½æ•°
```python
# å¸¸ç”¨æ¿€æ´»å‡½æ•°
relu = nn.ReLU()           # æœ€å¸¸ç”¨
leaky_relu = nn.LeakyReLU(negative_slope=0.01)
gelu = nn.GELU()           # Transformerä¸­å¸¸ç”¨
```

---

## ğŸš€ ç»å…¸CNNæ¶æ„

### ğŸ”¥ LeNet-5 (1998å¹´)
```python
import torch.nn as nn

class LeNet5(nn.Module):
    def __init__(self, num_classes=10):
        super(LeNet5, self).__init__()
        self.features = nn.Sequential(
            # ç¬¬ä¸€å±‚ï¼šå·ç§¯ + æ¿€æ´» + æ± åŒ–
            nn.Conv2d(1, 6, kernel_size=5, stride=1),
            nn.ReLU(inplace=True),
            nn.AvgPool2d(kernel_size=2, stride=2),
            
            # ç¬¬äºŒå±‚ï¼šå·ç§¯ + æ¿€æ´» + æ± åŒ–
            nn.Conv2d(6, 16, kernel_size=5, stride=1),
            nn.ReLU(inplace=True),
            nn.AvgPool2d(kernel_size=2, stride=2)
        )
        
        self.classifier = nn.Sequential(
            nn.Linear(16 * 5 * 5, 120),
            nn.ReLU(inplace=True),
            nn.Linear(120, 84),
            nn.ReLU(inplace=True),
            nn.Linear(84, num_classes)
        )
    
    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)  # å±•å¹³
        x = self.classifier(x)
        return x
```

### ğŸ“Š AlexNet (2012å¹´)
```python
class AlexNet(nn.Module):
    def __init__(self, num_classes=1000):
        super(AlexNet, self).__init__()
        self.features = nn.Sequential(
            # Conv1: è¾“å…¥ 224x224x3 â†’ è¾“å‡º 55x55x96
            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            
            # Conv2: 55x55x96 â†’ 27x27x256
            nn.Conv2d(96, 256, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            
            # Conv3: 27x27x256 â†’ 13x13x384
            nn.Conv2d(256, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            
            # Conv4: 13x13x384 â†’ 13x13x384
            nn.Conv2d(384, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            
            # Conv5: 13x13x384 â†’ 13x13x256
            nn.Conv2d(384, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2)
        )
        
        self.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(256 * 6 * 6, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, num_classes)
        )
```

### ğŸ† ResNet (2015å¹´) - æ®‹å·®ç½‘ç»œ
```python
class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super(ResidualBlock, self).__init__()
        
        self.conv1 = nn.Conv2d(in_channels, out_channels, 
                              kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        
        self.conv2 = nn.Conv2d(out_channels, out_channels,
                              kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        
        # è·³è·ƒè¿æ¥
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 
                         kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels)
            )
        else:
            self.shortcut = nn.Identity()
    
    def forward(self, x):
        residual = x
        
        out = torch.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        
        # æ®‹å·®è¿æ¥ï¼šè§£å†³æ¢¯åº¦æ¶ˆå¤±é—®é¢˜
        out += self.shortcut(residual)
        out = torch.relu(out)
        
        return out
```

---

## ğŸ”— ä¸æ·±åº¦å­¦ä¹ æ¡†æ¶çš„é›†æˆ

### ğŸ¤ [[PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶|PyTorch]]å®ç°

#### å®Œæ•´è®­ç»ƒæµç¨‹
```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
import torchvision.datasets as datasets

# 1. æ•°æ®é¢„å¤„ç†
transform_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
])

transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
])

# 2. åŠ è½½æ•°æ®é›†
train_dataset = datasets.CIFAR10(root='./data', train=True, 
                                download=True, transform=transform_train)
test_dataset = datasets.CIFAR10(root='./data', train=False, 
                               transform=transform_test)

train_loader = DataLoader(train_dataset, batch_size=128, 
                         shuffle=True, num_workers=4)
test_loader = DataLoader(test_dataset, batch_size=100, 
                        shuffle=False, num_workers=4)

# 3. å®šä¹‰æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
model = ResNet18(num_classes=10)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.1, 
                     momentum=0.9, weight_decay=5e-4)

# 4. è®­ç»ƒå¾ªç¯
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

for epoch in range(100):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        
        if batch_idx % 100 == 0:
            print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}')
```

### ğŸ› ï¸ [[TensorFlowæ·±åº¦å­¦ä¹ æ¡†æ¶|TensorFlow]]å®ç°

#### Kerasé«˜çº§APIæ„å»ºCNN
```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# ä½¿ç”¨å‡½æ•°å¼APIæ„å»ºResNeté£æ ¼æ¨¡å‹
def residual_block(x, filters, kernel_size=3, stride=1):
    # ä¸»è·¯å¾„
    fx = layers.Conv2D(filters, kernel_size, strides=stride, 
                      padding='same', use_bias=False)(x)
    fx = layers.BatchNormalization()(fx)
    fx = layers.ReLU()(fx)
    
    fx = layers.Conv2D(filters, kernel_size, strides=1, 
                      padding='same', use_bias=False)(fx)
    fx = layers.BatchNormalization()(fx)
    
    # è·³è·ƒè¿æ¥
    if stride != 1 or x.shape[-1] != filters:
        x = layers.Conv2D(filters, 1, strides=stride, 
                         padding='same', use_bias=False)(x)
        x = layers.BatchNormalization()(x)
    
    # æ®‹å·®ç›¸åŠ 
    out = layers.Add()([fx, x])
    out = layers.ReLU()(out)
    return out

# æ„å»ºå®Œæ•´æ¨¡å‹
def build_resnet_model(input_shape=(32, 32, 3), num_classes=10):
    inputs = keras.Input(shape=input_shape)
    
    # åˆå§‹å·ç§¯å±‚
    x = layers.Conv2D(64, 7, strides=2, padding='same')(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    x = layers.MaxPooling2D(3, strides=2, padding='same')(x)
    
    # æ®‹å·®å—ç»„
    x = residual_block(x, 64)
    x = residual_block(x, 64)
    
    x = residual_block(x, 128, stride=2)
    x = residual_block(x, 128)
    
    x = residual_block(x, 256, stride=2)
    x = residual_block(x, 256)
    
    # å…¨å±€å¹³å‡æ± åŒ–å’Œåˆ†ç±»å™¨
    x = layers.GlobalAveragePooling2D()(x)
    outputs = layers.Dense(num_classes, activation='softmax')(x)
    
    model = keras.Model(inputs, outputs)
    return model

# ç¼–è¯‘å’Œè®­ç»ƒ
model = build_resnet_model()
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# ä½¿ç”¨å›è°ƒå‡½æ•°
callbacks = [
    keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),
    keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=5),
    keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)
]

history = model.fit(
    train_dataset,
    epochs=100,
    validation_data=test_dataset,
    callbacks=callbacks
)
```

---

## ğŸ¯ é«˜çº§æŠ€æœ¯ä¸ä¼˜åŒ–

### âš¡ æ€§èƒ½ä¼˜åŒ–æŠ€å·§

#### 1ï¸âƒ£ æ•°æ®å¢å¼ºï¼ˆData Augmentationï¼‰
```python
# PyTorchç‰ˆæœ¬
import torchvision.transforms as transforms

transform_augment = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# TensorFlowç‰ˆæœ¬
def augment_image(image, label):
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_brightness(image, max_delta=0.2)
    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)
    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)
    return image, label
```

#### 2ï¸âƒ£ æ‰¹é‡å½’ä¸€åŒ–ï¼ˆBatch Normalizationï¼‰
```python
# æ‰¹é‡å½’ä¸€åŒ–çš„ä½œç”¨ï¼š
# 1. åŠ é€Ÿè®­ç»ƒæ”¶æ•›
# 2. å…è®¸ä½¿ç”¨æ›´å¤§çš„å­¦ä¹ ç‡
# 3. å‡å°‘å¯¹åˆå§‹åŒ–çš„æ•æ„Ÿæ€§
# 4. å…·æœ‰è½»å¾®çš„æ­£åˆ™åŒ–æ•ˆæœ

class ConvBNReLU(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):
        super().__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
    
    def forward(self, x):
        return self.relu(self.bn(self.conv(x)))
```

#### 3ï¸âƒ£ æ­£åˆ™åŒ–æŠ€æœ¯
```python
# Dropoutæ­£åˆ™åŒ–
class CNNWithDropout(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Dropout2d(0.25),  # 2D Dropout for conv layers
            
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Dropout2d(0.25),
        )
        
        self.classifier = nn.Sequential(
            nn.Linear(128 * 8 * 8, 512),
            nn.ReLU(),
            nn.Dropout(0.5),     # æ ‡å‡†Dropout for FC layers
            nn.Linear(512, num_classes)
        )

# L2æ­£åˆ™åŒ–ï¼ˆæƒé‡è¡°å‡ï¼‰
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)
```

### ğŸš€ ç°ä»£CNNæŠ€æœ¯

#### 1ï¸âƒ£ æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆDepthwise Separable Convolutionï¼‰
```python
class DepthwiseSeparableConv(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):
        super().__init__()
        
        # æ·±åº¦å·ç§¯ï¼šæ¯ä¸ªè¾“å…¥é€šé“å•ç‹¬å·ç§¯
        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, 
                                  stride, padding, groups=in_channels, bias=False)
        
        # ç‚¹å·ç§¯ï¼š1x1å·ç§¯æ··åˆé€šé“ä¿¡æ¯
        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, bias=False)
        
        self.bn1 = nn.BatchNorm2d(in_channels)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
    
    def forward(self, x):
        x = self.relu(self.bn1(self.depthwise(x)))
        x = self.relu(self.bn2(self.pointwise(x)))
        return x
```

#### 2ï¸âƒ£ æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAttention Mechanismï¼‰
```python
class ChannelAttention(nn.Module):
    """é€šé“æ³¨æ„åŠ›æ¨¡å— - ç±»ä¼¼SE-Net"""
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        
        self.fc = nn.Sequential(
            nn.Conv2d(channels, channels // reduction, 1, bias=False),
            nn.ReLU(inplace=True),
            nn.Conv2d(channels // reduction, channels, 1, bias=False)
        )
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        avg_out = self.fc(self.avg_pool(x))
        max_out = self.fc(self.max_pool(x))
        attention = self.sigmoid(avg_out + max_out)
        return x * attention

class SpatialAttention(nn.Module):
    """ç©ºé—´æ³¨æ„åŠ›æ¨¡å—"""
    def __init__(self, kernel_size=7):
        super().__init__()
        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        attention = torch.cat([avg_out, max_out], dim=1)
        attention = self.sigmoid(self.conv(attention))
        return x * attention
```

---

## ğŸ¨ åº”ç”¨åœºæ™¯

### ğŸ“¸ è®¡ç®—æœºè§†è§‰ä»»åŠ¡

#### å›¾åƒåˆ†ç±»
```python
# ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå›¾åƒåˆ†ç±»
import torchvision.models as models
import torchvision.transforms as transforms

# åŠ è½½é¢„è®­ç»ƒçš„ResNet50
model = models.resnet50(pretrained=True)
model.eval()

# å›¾åƒé¢„å¤„ç†
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                        std=[0.229, 0.224, 0.225])
])

# é¢„æµ‹
with torch.no_grad():
    input_tensor = preprocess(image).unsqueeze(0)
    predictions = model(input_tensor)
    predicted_class = predictions.argmax(1)
```

#### ç›®æ ‡æ£€æµ‹ä¸è¯­ä¹‰åˆ†å‰²
```python
# YOLOé£æ ¼çš„æ£€æµ‹å¤´
class DetectionHead(nn.Module):
    def __init__(self, in_channels, num_classes, num_anchors=3):
        super().__init__()
        self.num_classes = num_classes
        self.num_anchors = num_anchors
        
        # é¢„æµ‹bboxå›å½’ã€ç½®ä¿¡åº¦ã€ç±»åˆ«æ¦‚ç‡
        self.conv = nn.Conv2d(in_channels, 
                             num_anchors * (5 + num_classes), 
                             kernel_size=1)
    
    def forward(self, x):
        batch_size, _, height, width = x.shape
        
        # è¾“å‡ºå½¢çŠ¶: [batch, anchors, height, width, 5+num_classes]
        prediction = self.conv(x).view(
            batch_size, self.num_anchors, -1, height, width
        ).permute(0, 1, 3, 4, 2).contiguous()
        
        return prediction
```

### ğŸ”— ä¸[[Transformeræ¶æ„åŸç†|Transformer]]çš„èåˆ

#### Vision Transformer (ViT) æ··åˆæ¶æ„
```python
class CNNTransformerHybrid(nn.Module):
    def __init__(self, img_size=224, patch_size=16, num_classes=1000):
        super().__init__()
        
        # CNNç‰¹å¾æå–å™¨
        self.cnn_backbone = nn.Sequential(
            nn.Conv2d(3, 64, 7, stride=2, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(3, stride=2, padding=1),
            
            # ResNet-style blocks
            ResidualBlock(64, 128, stride=2),
            ResidualBlock(128, 256, stride=2),
            ResidualBlock(256, 512, stride=2),
        )
        
        # Patch embedding for Transformer
        self.patch_embed = nn.Conv2d(512, 768, patch_size//8, stride=patch_size//8)
        
        # Transformer encoder
        encoder_layer = nn.TransformerEncoderLayer(d_model=768, nhead=12)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=12)
        
        # åˆ†ç±»å¤´
        self.classifier = nn.Linear(768, num_classes)
    
    def forward(self, x):
        # CNNç‰¹å¾æå–
        x = self.cnn_backbone(x)
        
        # è½¬æ¢ä¸ºpatchåºåˆ—
        x = self.patch_embed(x)  # [B, 768, H/8, W/8]
        b, c, h, w = x.shape
        x = x.flatten(2).transpose(1, 2)  # [B, H*W, 768]
        
        # Transformerå¤„ç†
        x = self.transformer(x)
        
        # å…¨å±€å¹³å‡æ± åŒ– + åˆ†ç±»
        x = x.mean(dim=1)
        x = self.classifier(x)
        
        return x
```

---

## ğŸ”® å‘å±•è¶‹åŠ¿

### ğŸ“ˆ æŠ€æœ¯æ¼”è¿›æ–¹å‘

#### 1ï¸âƒ£ è½»é‡åŒ–ç½‘ç»œ
- **MobileNets**ï¼šæ·±åº¦å¯åˆ†ç¦»å·ç§¯
- **ShuffleNet**ï¼šé€šé“æ··æ´—æœºåˆ¶
- **EfficientNet**ï¼šå¤åˆç¼©æ”¾ç­–ç•¥

#### 2ï¸âƒ£ ç¥ç»æ¶æ„æœç´¢ï¼ˆNASï¼‰
- **AutoML**ï¼šè‡ªåŠ¨è®¾è®¡ç½‘ç»œç»“æ„
- **å¯å¾®åˆ†æ¶æ„æœç´¢**ï¼šæ¢¯åº¦ä¼˜åŒ–æ¶æ„å‚æ•°
- **ç¡¬ä»¶æ„ŸçŸ¥è®¾è®¡**ï¼šé’ˆå¯¹ç‰¹å®šç¡¬ä»¶ä¼˜åŒ–

#### 3ï¸âƒ£ è‡ªç›‘ç£å­¦ä¹ 
- **å¯¹æ¯”å­¦ä¹ **ï¼šSimCLR, MoCoç­‰æ–¹æ³•
- **æ©ç å›¾åƒå»ºæ¨¡**ï¼šMAE (Masked Autoencoder)
- **é¢„è®­ç»ƒ + å¾®è°ƒ**ï¼šç±»ä¼¼[[å¤§è¯­è¨€æ¨¡å‹åŸºç¡€|å¤§è¯­è¨€æ¨¡å‹]]çš„èŒƒå¼

### ğŸš€ ä¸å…¶ä»–æŠ€æœ¯çš„èåˆ

#### CNN + [[Transformeræ¶æ„åŸç†|Transformer]]
- **ConvNeXt**ï¼šç°ä»£åŒ–çš„CNNè®¾è®¡
- **Swin Transformer**ï¼šåˆ†å±‚è§†è§‰Transformer
- **CoAtNet**ï¼šå·ç§¯å’Œæ³¨æ„åŠ›çš„æœ‰æœºç»“åˆ

#### CNN + ç”Ÿæˆæ¨¡å‹
- **GAN**ï¼šç”Ÿæˆå¯¹æŠ—ç½‘ç»œä¸­çš„åˆ¤åˆ«å™¨
- **æ‰©æ•£æ¨¡å‹**ï¼šUNetæ¶æ„çš„å¹¿æ³›åº”ç”¨
- **VAE**ï¼šå˜åˆ†è‡ªç¼–ç å™¨çš„ç¼–è§£ç å™¨

---

## ğŸ“– å­¦ä¹ è·¯å¾„å»ºè®®

### ğŸ“ æ¨èå­¦ä¹ é¡ºåº

#### åˆçº§é˜¶æ®µ
1. **æ•°å­¦åŸºç¡€**ï¼šçº¿æ€§ä»£æ•°ã€æ¦‚ç‡è®ºã€å¤šå…ƒå¾®ç§¯åˆ†
2. **CNNåŸç†**ï¼šå·ç§¯ã€æ± åŒ–ã€åå‘ä¼ æ’­æœºåˆ¶
3. **ç»å…¸æ¶æ„**ï¼šLeNet, AlexNet, VGGå®ç°
4. **å®è·µé¡¹ç›®**ï¼šMNIST, CIFAR-10å›¾åƒåˆ†ç±»

#### è¿›é˜¶é˜¶æ®µ
1. **ç°ä»£æ¶æ„**ï¼šResNet, DenseNet, MobileNet
2. **ä¼˜åŒ–æŠ€æœ¯**ï¼šæ•°æ®å¢å¼ºã€æ­£åˆ™åŒ–ã€è¶…å‚è°ƒä¼˜
3. **ç›®æ ‡æ£€æµ‹**ï¼šYOLO, R-CNNç³»åˆ—
4. **è¯­ä¹‰åˆ†å‰²**ï¼šFCN, U-Net, DeepLab

#### é«˜çº§é˜¶æ®µ
1. **æ³¨æ„åŠ›æœºåˆ¶**ï¼šSE-Net, CBAM, Non-local
2. **è½»é‡åŒ–è®¾è®¡**ï¼šçŸ¥è¯†è’¸é¦ã€æ¨¡å‹å‹ç¼©ã€é‡åŒ–
3. **æ¶æ„æœç´¢**ï¼šNAS, AutoML
4. **è·¨æ¨¡æ€åº”ç”¨**ï¼šç»“åˆ[[Transformeræ¶æ„åŸç†|Transformer]]ã€å¤šæ¨¡æ€å­¦ä¹ 

### ğŸ› ï¸ å®ç”¨èµ„æº

#### åœ¨çº¿è¯¾ç¨‹
- **CS231n**ï¼šæ–¯å¦ç¦å¤§å­¦è®¡ç®—æœºè§†è§‰è¯¾ç¨‹
- **Deep Learning Specialization**ï¼šAndrew Ngæ·±åº¦å­¦ä¹ ä¸“é¡¹è¯¾ç¨‹
- **Fast.ai**ï¼šå®è·µå¯¼å‘çš„æ·±åº¦å­¦ä¹ è¯¾ç¨‹

#### å®è·µå¹³å°
- **PyTorch Tutorials**ï¼šå®˜æ–¹æ•™ç¨‹å’Œç¤ºä¾‹
- **TensorFlow Model Garden**ï¼šé¢„è®­ç»ƒæ¨¡å‹åº“
- **Papers with Code**ï¼šè®ºæ–‡å¤ç°ä»£ç 
- **Kaggle Competitions**ï¼šè®¡ç®—æœºè§†è§‰ç«èµ›

---

## ğŸ¯ æ€»ç»“

CNNä½œä¸ºæ·±åº¦å­¦ä¹ çš„åŸºçŸ³æ¶æ„ï¼š

- ğŸ›ï¸ **ç†è®ºåŸºç¡€**ï¼šç©ºé—´ä¸å˜æ€§å’Œå±€éƒ¨è¿æ¥çš„å·§å¦™è®¾è®¡
- ğŸ”§ **å®è·µä»·å€¼**ï¼šè®¡ç®—æœºè§†è§‰ä»»åŠ¡çš„æ ¸å¿ƒå·¥å…·
- ğŸš€ **å‘å±•æ´»åŠ›**ï¼šä¸æ–­ä¸æ–°æŠ€æœ¯èåˆæ¼”è¿›
- ğŸŒ **åº”ç”¨å¹¿æ³›**ï¼šä»å›¾åƒåˆ†ç±»åˆ°å¤šæ¨¡æ€ç†è§£

æŒæ¡CNNä¸ä»…æ˜¯ç†è§£è®¡ç®—æœºè§†è§‰çš„å…³é”®ï¼Œä¹Ÿä¸ºå­¦ä¹ [[PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶|PyTorch]]ã€[[TensorFlowæ·±åº¦å­¦ä¹ æ¡†æ¶|TensorFlow]]ç­‰æ¡†æ¶å¥ å®šåŸºç¡€ã€‚éšç€[[Transformeræ¶æ„åŸç†|Transformer]]ç­‰æ–°æ¶æ„çš„å…´èµ·ï¼ŒCNNæ­£åœ¨ä¸å…¶ä»–æŠ€æœ¯æ·±åº¦èåˆï¼Œå±•ç°å‡ºæŒç»­çš„åˆ›æ–°æ´»åŠ›ã€‚

å¯¹äºAIå­¦ä¹ è€…è€Œè¨€ï¼ŒCNNæ˜¯è¿æ¥ä¼ ç»Ÿæœºå™¨å­¦ä¹ ä¸ç°ä»£æ·±åº¦å­¦ä¹ çš„é‡è¦æ¡¥æ¢ï¼Œä¹Ÿæ˜¯é€šå¾€[[å¤§è¯­è¨€æ¨¡å‹åŸºç¡€|å¤§è¯­è¨€æ¨¡å‹]]ã€å¤šæ¨¡æ€AIç­‰å‰æ²¿æŠ€æœ¯çš„å¿…ç»ä¹‹è·¯ã€‚
