# TensorFlow æ·±åº¦å­¦ä¹ æ¡†æ¶

> **ä½œç”¨**ï¼šGoogleå¼€å‘çš„ç«¯åˆ°ç«¯å¼€æºæœºå™¨å­¦ä¹ å¹³å°ï¼Œæ“…é•¿ç”Ÿäº§éƒ¨ç½²å’Œå¤§è§„æ¨¡è®­ç»ƒ
> **å±‚çº§**ï¼šK3-å·¥å…·å¹³å°ä¸ç”Ÿæ€ â†’ æ·±åº¦å­¦ä¹ æ¡†æ¶  
> **å…³è”**ï¼š[[PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶]]ã€[[Transformeræ¶æ„åŸç†]]ã€[[å¤§è¯­è¨€æ¨¡å‹åŸºç¡€]]ã€[[CNNå·ç§¯ç¥ç»ç½‘ç»œ]]

---

## ğŸ“Œ æ¦‚å¿µå®šä¹‰

**TensorFlow**æ˜¯ç”±Googleå¼€å‘çš„ç«¯åˆ°ç«¯å¼€æºæœºå™¨å­¦ä¹ å¹³å°ï¼Œä»¥å…¶å¼ºå¤§çš„ç”Ÿäº§éƒ¨ç½²èƒ½åŠ›ã€é™æ€è®¡ç®—å›¾ä¼˜åŒ–å’Œè·¨å¹³å°æ”¯æŒè€Œé—»åã€‚TensorFlow 2.0å¼•å…¥äº†Eager Executionï¼Œä½¿å…¶å…¼å…·çµæ´»æ€§å’Œæ€§èƒ½ä¼˜åŠ¿ã€‚

### ğŸ¯ æ ¸å¿ƒç‰¹ç‚¹
- **ç”Ÿäº§å°±ç»ª**ï¼šä¸“ä¸ºå¤§è§„æ¨¡éƒ¨ç½²è®¾è®¡çš„æˆç†Ÿå¹³å°
- **è·¨å¹³å°æ”¯æŒ**ï¼šä»ç§»åŠ¨è®¾å¤‡åˆ°åˆ†å¸ƒå¼é›†ç¾¤çš„å…¨æ ˆè§£å†³æ–¹æ¡ˆ
- **é™æ€+åŠ¨æ€å›¾**ï¼šGraphæ¨¡å¼ä¼˜åŒ–æ€§èƒ½ï¼ŒEageræ¨¡å¼ä¾¿äºè°ƒè¯•
- **å®Œæ•´ç”Ÿæ€**ï¼šTensorBoardã€TensorFlow Servingç­‰å®Œæ•´å·¥å…·é“¾

---

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„

### ğŸ”§ ä¸»è¦ç»„ä»¶

```mermaid
graph TD
    A[TensorFlowæ ¸å¿ƒ] --> B[Kerasé«˜çº§API]
    A --> C[ä½çº§æ“ä½œtf.function]
    A --> D[æ•°æ®å¤„ç†tf.data]
    A --> E[æ¨¡å‹ä¿å­˜/åŠ è½½]
    A --> F[åˆ†å¸ƒå¼è®­ç»ƒ]
    
    B --> B1[Sequentialæ¨¡å‹]
    B --> B2[Functional API]
    B --> B3[å­ç±»åŒ–æ¨¡å‹]
    
    C --> C1[è‡ªåŠ¨å¾®åˆ†GradientTape]
    C --> C2[å›¾ä¼˜åŒ–]
    
    D --> D1[æ•°æ®æµæ°´çº¿]
    D --> D2[é¢„å¤„ç†]
    
    E --> E1[SavedModelæ ¼å¼]
    E --> E2[æ£€æŸ¥ç‚¹ç³»ç»Ÿ]
    
    F --> F1[åˆ†å¸ƒå¼ç­–ç•¥]
    F --> F2[TPUæ”¯æŒ]
```

### ğŸ’¡ æ ¸å¿ƒæ¦‚å¿µ

#### 1ï¸âƒ£ Kerasé«˜çº§API
```python
import tensorflow as tf
from tensorflow import keras

# Sequentialæ¨¡å‹
model = keras.Sequential([
    keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    keras.layers.Dropout(0.2),
    keras.layers.Dense(10, activation='softmax')
])

# ç¼–è¯‘æ¨¡å‹
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
```

#### 2ï¸âƒ£ è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯
```python
import tensorflow as tf

# ä½¿ç”¨GradientTapeè¿›è¡Œè‡ªå®šä¹‰è®­ç»ƒ
@tf.function
def train_step(x, y):
    with tf.GradientTape() as tape:
        predictions = model(x, training=True)
        loss = loss_fn(y, predictions)
    
    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    
    return loss

# è®­ç»ƒå¾ªç¯
for epoch in range(epochs):
    for x_batch, y_batch in train_dataset:
        loss = train_step(x_batch, y_batch)
```

#### 3ï¸âƒ£ æ•°æ®æµæ°´çº¿
```python
# é«˜æ•ˆçš„æ•°æ®å¤„ç†æµæ°´çº¿
dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
dataset = dataset.batch(32).shuffle(1000).prefetch(tf.data.AUTOTUNE)

# æ•°æ®å¢å¼º
def augment(image, label):
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_brightness(image, 0.2)
    return image, label

dataset = dataset.map(augment, num_parallel_calls=tf.data.AUTOTUNE)
```

---

## ğŸš€ å®æˆ˜åº”ç”¨

### ğŸ”¥ Functional APIæ„å»ºå¤æ‚æ¨¡å‹

```python
# å¤šè¾“å…¥å¤šè¾“å‡ºæ¨¡å‹
inputs = keras.Input(shape=(784,))
dense = keras.layers.Dense(64, activation="relu")
x = dense(inputs)

# åˆ†æ”¯1ï¼šåˆ†ç±»
classification_output = keras.layers.Dense(10, activation="softmax", name="classification")(x)

# åˆ†æ”¯2ï¼šå›å½’
regression_output = keras.layers.Dense(1, name="regression")(x)

# åˆ›å»ºæ¨¡å‹
model = keras.Model(inputs=inputs, outputs=[classification_output, regression_output])

# ç¼–è¯‘å¤šè¾“å‡ºæ¨¡å‹
model.compile(
    optimizer="adam",
    loss={
        "classification": "sparse_categorical_crossentropy",
        "regression": "mse"
    },
    metrics={
        "classification": "accuracy",
        "regression": "mae"
    }
)
```

### ğŸ“Š è‡ªå®šä¹‰å±‚å’Œæ¨¡å‹

```python
# è‡ªå®šä¹‰å±‚
class MultiHeadAttention(keras.layers.Layer):
    def __init__(self, num_heads, d_model):
        super(MultiHeadAttention, self).__init__()
        self.num_heads = num_heads
        self.d_model = d_model
        
        assert d_model % self.num_heads == 0
        
        self.depth = d_model // self.num_heads
        
        self.wq = keras.layers.Dense(d_model)
        self.wk = keras.layers.Dense(d_model)
        self.wv = keras.layers.Dense(d_model)
        
        self.dense = keras.layers.Dense(d_model)
    
    def call(self, inputs, mask=None):
        batch_size = tf.shape(inputs)[0]
        
        q = self.wq(inputs)
        k = self.wk(inputs)
        v = self.wv(inputs)
        
        # åˆ†å‰²ä¸ºå¤šå¤´
        q = self.split_heads(q, batch_size)
        k = self.split_heads(k, batch_size)
        v = self.split_heads(v, batch_size)
        
        # ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›
        attention = self.scaled_dot_product_attention(q, k, v, mask)
        attention = tf.transpose(attention, perm=[0, 2, 1, 3])
        
        concat_attention = tf.reshape(attention, (batch_size, -1, self.d_model))
        output = self.dense(concat_attention)
        
        return output
```

### ğŸ› ï¸ æ¨¡å‹éƒ¨ç½²

```python
# ä¿å­˜å®Œæ•´æ¨¡å‹
model.save('my_model')

# è½¬æ¢ä¸ºTensorFlow Liteï¼ˆç§»åŠ¨ç«¯éƒ¨ç½²ï¼‰
converter = tf.lite.TFLiteConverter.from_saved_model('my_model')
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

with open('model.tflite', 'wb') as f:
    f.write(tflite_model)

# TensorFlow.jsè½¬æ¢ï¼ˆWebéƒ¨ç½²ï¼‰
# tensorflowjs_converter --input_format=tf_saved_model \
#                        --output_node_names='output' \
#                        my_model \
#                        web_model/
```

---

## ğŸ”— ä¸å…¶ä»–æŠ€æœ¯çš„é›†æˆ

### ğŸ¤ [[Transformeræ¶æ„åŸç†|Transformer]]å®ç°

```python
class TransformerEncoder(keras.layers.Layer):
    def __init__(self, num_heads, d_model, dff, rate=0.1):
        super(TransformerEncoder, self).__init__()
        
        self.mha = MultiHeadAttention(num_heads, d_model)
        self.ffn = keras.Sequential([
            keras.layers.Dense(dff, activation='relu'),
            keras.layers.Dense(d_model)
        ])
        
        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)
        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)
        
        self.dropout1 = keras.layers.Dropout(rate)
        self.dropout2 = keras.layers.Dropout(rate)
    
    def call(self, x, training, mask):
        attn_output = self.mha(x, mask=mask)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(x + attn_output)
        
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        out2 = self.layernorm2(out1 + ffn_output)
        
        return out2
```

### ğŸ“ˆ TensorBoardå¯è§†åŒ–

```python
# è®¾ç½®TensorBoardå›è°ƒ
tensorboard_callback = keras.callbacks.TensorBoard(
    log_dir='./logs',
    histogram_freq=1,
    write_graph=True,
    write_images=True
)

# è®­ç»ƒæ—¶ä½¿ç”¨å›è°ƒ
model.fit(
    train_dataset,
    epochs=10,
    validation_data=val_dataset,
    callbacks=[tensorboard_callback]
)

# è‡ªå®šä¹‰æŒ‡æ ‡è®°å½•
with tf.summary.create_file_writer('./logs').as_default():
    tf.summary.scalar('custom_metric', value, step=epoch)
```

---

## ğŸ¯ TensorFlow vs [[PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶|PyTorch]]

### ğŸ“Š å…³é”®å¯¹æ¯”

| ç‰¹æ€§ | TensorFlow | [[PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶\|PyTorch]] |
|------|------------|---------|
| **å­¦ä¹ æ›²çº¿** | è¾ƒé™¡å³­ | ç›¸å¯¹å¹³ç¼“ |
| **è°ƒè¯•** | TensorBoardå¼ºå¤§ | åŸç”ŸPythonè°ƒè¯• |
| **éƒ¨ç½²** | å·¥ä¸šçº§æˆç†Ÿ | å¿«é€Ÿå‘å±•ä¸­ |
| **ç§»åŠ¨ç«¯** | TF Liteæˆç†Ÿ | æ”¯æŒæœ‰é™ |
| **ç ”ç©¶** | é€‚ä¸­ | æ›´å—æ¬¢è¿ |
| **å·¥ä¸šåº”ç”¨** | å¹¿æ³›é‡‡ç”¨ | å¿«é€Ÿå¢é•¿ |

### ğŸ”„ é€‰æ‹©æŒ‡å—

**é€‰æ‹©TensorFlowçš„åœºæ™¯**ï¼š
- éœ€è¦ç”Ÿäº§éƒ¨ç½²åˆ°ç§»åŠ¨ç«¯æˆ–Web
- å›¢é˜Ÿæœ‰Googleç”Ÿæ€ä¾èµ–
- éœ€è¦å¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒ
- é‡è§†æ¨¡å‹ä¼˜åŒ–å’Œæ¨ç†æ€§èƒ½

**é€‰æ‹©[[PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶|PyTorch]]çš„åœºæ™¯**ï¼š
- ç ”ç©¶å¯¼å‘çš„é¡¹ç›®
- éœ€è¦é¢‘ç¹è°ƒè¯•å’Œå®éªŒ
- å›¢é˜Ÿæ›´ç†Ÿæ‚‰Pythonicé£æ ¼
- å¿«é€ŸåŸå‹å¼€å‘

---

## ğŸš€ é«˜çº§ç‰¹æ€§

### âš¡ æ€§èƒ½ä¼˜åŒ–

1. **å›¾ä¼˜åŒ–**
```python
# ä½¿ç”¨tf.functionè¿›è¡Œå›¾ç¼–è¯‘
@tf.function
def train_step(x, y):
    with tf.GradientTape() as tape:
        predictions = model(x, training=True)
        loss = loss_fn(y, predictions)
    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    return loss

# XLAåŠ é€Ÿç¼–è¯‘
@tf.function(jit_compile=True)
def fast_function(x):
    return tf.nn.relu(tf.matmul(x, x))
```

2. **åˆ†å¸ƒå¼è®­ç»ƒ**
```python
# å¤šGPUåˆ†å¸ƒå¼ç­–ç•¥
strategy = tf.distribute.MirroredStrategy()

with strategy.scope():
    model = create_model()
    model.compile(optimizer='adam',
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),
                  metrics=['accuracy'])

# TPUç­–ç•¥
resolver = tf.distribute.cluster_resolver.TPUClusterResolver()
tf.config.experimental_connect_to_cluster(resolver)
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.TPUStrategy(resolver)
```

3. **æ··åˆç²¾åº¦è®­ç»ƒ**
```python
# å¯ç”¨æ··åˆç²¾åº¦
policy = keras.mixed_precision.Policy('mixed_float16')
keras.mixed_precision.set_global_policy(policy)

# æ„å»ºæ¨¡å‹æ—¶è‡ªåŠ¨ä½¿ç”¨æ··åˆç²¾åº¦
model = create_model()  # è‡ªåŠ¨ä½¿ç”¨float16è®¡ç®—ï¼Œfloat32å­˜å‚¨æƒé‡
```

### ğŸ”§ ç”Ÿäº§éƒ¨ç½²

```python
# TensorFlow Serving
# 1. ä¿å­˜æ¨¡å‹ä¸ºSavedModelæ ¼å¼
tf.saved_model.save(model, 'model/1')

# 2. å¯åŠ¨TensorFlow Serving
# docker run -p 8501:8501 --mount type=bind,source=$(pwd)/model,target=/models/my_model 
#            -e MODEL_NAME=my_model -t tensorflow/serving

# 3. REST APIè°ƒç”¨
import requests
data = {"instances": [{"input": [1, 2, 3, 4]}]}
response = requests.post('http://localhost:8501/v1/models/my_model:predict', 
                        json=data)
```

---

## ğŸ“š ç”Ÿæ€ç³»ç»Ÿ

### ğŸ”§ TensorFlowç”Ÿæ€å·¥å…·

| å·¥å…· | ç”¨é€” | è¯´æ˜ |
|------|------|------|
| **TensorBoard** | å¯è§†åŒ–è°ƒè¯• | è®­ç»ƒç›‘æ§ã€æ¨¡å‹å¯è§†åŒ– |
| **TF Serving** | æ¨¡å‹æœåŠ¡ | é«˜æ€§èƒ½æ¨ç†æœåŠ¡ |
| **TF Lite** | ç§»åŠ¨ç«¯éƒ¨ç½² | ç§»åŠ¨å’ŒåµŒå…¥å¼è®¾å¤‡ |
| **TF.js** | Webéƒ¨ç½² | æµè§ˆå™¨å’ŒNode.js |
| **TFX** | ç”Ÿäº§æµæ°´çº¿ | ç«¯åˆ°ç«¯MLæµæ°´çº¿ |
| **TensorFlow Hub** | é¢„è®­ç»ƒæ¨¡å‹ | æ¨¡å‹å¤ç”¨å¹³å° |

### ğŸŒ ä¸äº‘å¹³å°é›†æˆ

```python
# Google Cloud AI Platform
from google.cloud import aiplatform

aiplatform.init(project='your-project', location='us-central1')

# éƒ¨ç½²æ¨¡å‹
model = aiplatform.Model.upload(
    display_name='my-model',
    artifact_uri='gs://your-bucket/model/',
    serving_container_image_uri='gcr.io/cloud-aiplatform/prediction/tf2-cpu.2-8:latest'
)

endpoint = model.deploy(machine_type='n1-standard-4')
```

---

## ğŸ”® å‘å±•è¶‹åŠ¿

### ğŸ“ˆ æŠ€æœ¯æ¼”è¿›

1. **TensorFlow 3.0å±•æœ›**
   - æ›´ç®€åŒ–çš„APIè®¾è®¡
   - æ›´å¥½çš„Kerasé›†æˆ
   - å¢å¼ºçš„åˆ†å¸ƒå¼æ”¯æŒ

2. **ç¡¬ä»¶åŠ é€Ÿ**
   - TPU v5ç­‰æ–°ç¡¬ä»¶æ”¯æŒ
   - æ›´å¤šAIèŠ¯ç‰‡é€‚é…
   - è¾¹ç¼˜è®¡ç®—ä¼˜åŒ–

3. **AI for Science**
   - TensorFlow Quantumé‡å­è®¡ç®—
   - ç§‘å­¦è®¡ç®—ä¸“ç”¨ä¼˜åŒ–
   - ç‰©ç†ä»¿çœŸåŠ é€Ÿ

### ğŸš€ åº”ç”¨æ–¹å‘

- **è”é‚¦å­¦ä¹ **ï¼šTensorFlow Federated
- **æ¨èç³»ç»Ÿ**ï¼šTensorFlow Recommenders
- **æ—¶é—´åºåˆ—**ï¼šTensorFlow Time Series
- **å¼ºåŒ–å­¦ä¹ **ï¼šTF-Agents

---

## ğŸ“– å­¦ä¹ è·¯å¾„

### ğŸ“ æ¨èå­¦ä¹ é¡ºåº

1. **åŸºç¡€å…¥é—¨**
   - Keras Sequential API
   - åŸºæœ¬çš„è®­ç»ƒå’Œè¯„ä¼°
   - æ•°æ®å¤„ç†æµæ°´çº¿

2. **è¿›é˜¶åŠŸèƒ½**
   - Functional APIå’Œè‡ªå®šä¹‰å±‚
   - è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯
   - æ¨¡å‹ä¿å­˜å’Œéƒ¨ç½²

3. **é«˜çº§ç‰¹æ€§**
   - åˆ†å¸ƒå¼è®­ç»ƒç­–ç•¥
   - æ€§èƒ½ä¼˜åŒ–æŠ€å·§
   - ç”Ÿäº§éƒ¨ç½²æ–¹æ¡ˆ

4. **ä¸“ä¸šåº”ç”¨**
   - [[CNNå·ç§¯ç¥ç»ç½‘ç»œ|è®¡ç®—æœºè§†è§‰]]é¡¹ç›®
   - [[RNNå¾ªç¯ç¥ç»ç½‘ç»œ|è‡ªç„¶è¯­è¨€å¤„ç†]]åº”ç”¨
   - æ¨èç³»ç»Ÿå¼€å‘

### ğŸ› ï¸ å®ç”¨èµ„æº

- **å®˜æ–¹æ•™ç¨‹**ï¼šhttps://www.tensorflow.org/tutorials
- **TensorFlow Hub**ï¼šé¢„è®­ç»ƒæ¨¡å‹èµ„æº
- **TensorFlow Community**ï¼šç¤¾åŒºæ”¯æŒè®ºå›
- **Google Colab**ï¼šå…è´¹GPU/TPUç¯å¢ƒ
- **Courseraè¯¾ç¨‹**ï¼šTensorFlowä¸“é¡¹è¯¾ç¨‹

---

## ğŸ¯ æ€»ç»“

TensorFlowä½œä¸ºä¼ä¸šçº§æ·±åº¦å­¦ä¹ å¹³å°ï¼š
- ğŸ­ **ç”Ÿäº§å°±ç»ª**ï¼šæˆç†Ÿçš„éƒ¨ç½²å’ŒæœåŠ¡èƒ½åŠ›
- ğŸŒ **å…¨æ ˆæ”¯æŒ**ï¼šä»ç ”ç©¶åˆ°ç”Ÿäº§çš„å®Œæ•´è§£å†³æ–¹æ¡ˆ
- âš¡ **æ€§èƒ½ä¼˜å¼‚**ï¼šé™æ€å›¾ä¼˜åŒ–å’Œç¡¬ä»¶åŠ é€Ÿ
- ğŸ”§ **å·¥å…·å®Œå–„**ï¼šä¸°å¯Œçš„ç”Ÿæ€ç³»ç»Ÿå’Œå·¥å…·é“¾

è™½ç„¶åœ¨ç ”ç©¶ç¤¾åŒº[[PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶|PyTorch]]æ›´å—æ¬¢è¿ï¼Œä½†TensorFlowåœ¨å·¥ä¸šéƒ¨ç½²ã€ç§»åŠ¨ç«¯åº”ç”¨å’Œå¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒä¸­ä»å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚é€‰æ‹©æ¡†æ¶åº”æ ¹æ®é¡¹ç›®éœ€æ±‚ã€å›¢é˜Ÿç»éªŒå’Œéƒ¨ç½²è¦æ±‚æ¥å†³å®šã€‚