📁 **📚 基础概念**

#进阶 #半监督学习 #自监督学习

---

## **✅ 文档标题：基础概念 - 半监督学习与自监督学习详解**

---

## **一、背景与概述**

在现实世界中，我们常面临：

- 获取**大量未标注数据**相对容易（如网页、视频、传感器数据）
    
- 而获取**高质量的人工标注数据**非常昂贵

因此在 **[[监督学习与无监督学习对比|监督学习（有标签）]]** 与 **[[监督学习与无监督学习对比|无监督学习（无标签）]]** 之间，诞生了两个非常重要的中间范式：

> **半监督学习（Semi-Supervised Learning）** 与 **自监督学习（Self-Supervised Learning）**

这两类方法都试图**充分利用未标注数据**来提升模型性能，尤其是在大模型与预训练领域极为关键。

---

## **二、什么是半监督学习（Semi-Supervised Learning）？**

### **✅ 定义：**

> 半监督学习是一种结合**少量标注数据 + 大量未标注数据**的训练方式，以提高模型的泛化能力。

### **✅ 通俗理解：**

你知道答案的样本只有很少（老师只讲了5道题），但你有大量题目（练习册）。通过**猜题 + 修正 + 模拟标注**，你能自我提高。

### **✅ 示例场景：**

- 医疗图像识别：手工标注 CT 图像非常费时，医生标注100张，未标注有几千张
    
- 内容审核系统：少量违规内容已标注，大量待判定内容无标签

### **✅ 常见技术路线：**

|**方法**|**简要描述**|
|---|---|
|**伪标签（Pseudo Labeling）**|用已有模型对未标注数据打“伪标签”并加入训练|
|**一致性正则（Consistency Regularization）**|不同扰动下，模型预测应保持一致|
|**图神经网络（Graph-Based SSL）**|利用节点间关系传播标签（如社交图谱）|
|**MixMatch / FixMatch 等框架**|高效整合伪标签与增强策略|

---

## **三、什么是自监督学习（Self-Supervised Learning）？**

### **✅ 定义：**

> 自监督学习是一种从**原始数据中自动生成标签、构建任务**的学习方式，不依赖人工标注。

### **✅ 通俗理解：**

老师不讲题，你自己出题自己做。例如：

- 拿一句话挖空一个词来猜（语言模型）
    
- 拿一张图剪成两半猜位置（视觉模型）

### **✅ 核心特点：**

- **不需要任何人工标签**
    
- 构造任务即是学习目标
    
- 通常作为**预训练方法**用于构建“通用理解能力”

### **✅ 常见任务示意：**

|**自监督任务**|**应用领域**|**示例**|
|---|---|---|
|**遮蔽预测（Masking）**|NLP|BERT：我爱[mask]学习 → 猜“机器”|
|**下一个预测（Next Prediction）**|NLP|GPT：我今天很开心，因为……|
|**对比学习（Contrastive Learning）**|CV|SimCLR、MoCo：同一图片不同视角为正样本，其他为负样本|
|**图像重建/旋转预测**|CV|预测图片旋转角度、还原图像内容|

---

## **四、对比分析：半监督 Vs 自监督**

|**维度**|**半监督学习**|**自监督学习**|
|---|---|---|
|是否需要标签|✅ 部分需要（少量标签）|❌ 完全不需要|
|核心策略|利用未标注数据提升已有任务表现|构造任务、学习数据本身的结构|
|应用场景|有少量人工标注时|数据大量但无标签、预训练场景|
|代表模型|MixMatch、FixMatch|BERT、SimCLR、BYOL、GPT|
|优势|提高模型在下游任务的表现|构建通用表征，适配多任务迁移|
|常用于|半监督分类、医疗场景|预训练语言模型、图像模型、语音模型等|

---

## **五、图示：监督范式的进化路径**

```
graph TD
A[无监督学习<br>（完全无标签）]
B[自监督学习<br>（生成伪标签）]
C[半监督学习<br>（少量真实标签 + 无标签）]
D[监督学习<br>（大量真实标签）]

A --> B --> C --> D
```

---

## **六、总结与趋势**

|**趋势**|**内容**|
|---|---|
|🔥 自监督是大模型训练的**核心技术路线**|GPT, BERT, CLIP 等均使用自监督预训练|
|💡 半监督适合**数据稀缺的特定任务**|特别是标注昂贵的专业领域（医疗、法律）|
|🔄 二者可结合|自监督进行预训练 + 半监督微调|

---

## **七、进一步阅读与推荐：**

- 🔖 BERT: [《Attention is All You Need》](https://arxiv.org/abs/1706.03762)
    
- 📘《Self-Supervised Learning: The Dark Matter of Intelligence》 by Yann LeCun
    
- 🔍 半监督综述：[A Survey on Semi-Supervised Learning](https://arxiv.org/abs/2006.05278)
    
- 🎓 课程推荐：CS224U（Stanford）/ DeepLearning.AI 表征学习课程

---

如需我为你进一步讲解具体方法（如 FixMatch、SimCLR）、代码实现（PyTorch/TensorFlow）或应用案例，欢迎继续提问。